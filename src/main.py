from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from src.utils.logging_config import setup_logging
from src.api.gemini_api import generate_text

# Configure logging at app startup
setup_logging()

app = FastAPI(title="Gemini API Implementation")

# Configure CORS (allow all origins for development)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

@app.get("/ping")
def ping():
    """
    Test endpoint to verify that the server is running.
    """
    return {"message": "pong"}

class ChatRequest(BaseModel):
    prompt: str

class ChatResponse(BaseModel):
    response: str

@app.post("/chat", response_model=ChatResponse)
def chat(request: ChatRequest):
    """
    Chatbot endpoint: receives a prompt and returns the response generated by Gemini 2.5 Pro.
    """
    try:
        result = generate_text(request.prompt, model="gemini-2.5-pro")
        return ChatResponse(response=result)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

class ContentRequest(BaseModel):
    prompt: str

class ContentResponse(BaseModel):
    content: str

@app.post("/generate-content", response_model=ContentResponse)
def generate_content(request: ContentRequest):
    """
    Content generator endpoint: receives a prompt and returns generated content using Gemini 2.5 Pro.
    """
    try:
        content = generate_text(request.prompt, model="gemini-2.5-pro")
        return ContentResponse(content=content)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

class AnalyzeTextRequest(BaseModel):
    text: str

class AnalyzeTextResponse(BaseModel):
    analysis: str

@app.post("/analyze-text", response_model=AnalyzeTextResponse)
def analyze_text(request: AnalyzeTextRequest):
    """
    Text analysis endpoint: receives text and returns analysis (sentiment, summary, paraphrase) using Gemini 2.5 Pro.
    """
    prompt = (
        "Analyze the following text. "
        "Return a sentiment analysis, a short summary, and a paraphrase.\n"
        f"Text: {request.text}"
    )
    try:
        analysis = generate_text(prompt, model="gemini-2.5-pro")
        return AnalyzeTextResponse(analysis=analysis)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e)) 